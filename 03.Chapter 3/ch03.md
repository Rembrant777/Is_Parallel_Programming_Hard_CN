## Chapter 3
## Hardware and its Habits 
## 硬件及其特性

Most people intuitively understand that passing messages between systems is more expensive than performing simple calculations within the confines of a single system. 
大多数人会下意识认为系统间进行消息的传输所带来的系统开销要远高于单节点计算机上执行简单的计算. 


But it is also the case that communicating among threads within the confines of a single shared-memory system can also be quite expensive. 
但是同样在这个问题范畴内, 单个计算节点上多线程间彼此间竟有共享内存系统进行的通信其所带来的资源开销也同样高昂. 

This chapter therefore looks at the cost of synchornization and communication within a shared-memory system. 
所以本章就围绕(单个计算节点上的)在共享内存系统上所执行的同步操作与沟通所带来的系统开销来展开.  

These few pages can do no more than scratch the surface of shared-memory parallel hardware design; 
这一章节中的几页呢, 对于设计硬件中涉及到共享内存并行这个话题简直就是隔靴搔痒. 

readers desiring more detail would do well to start with a recent edition of Hennessy’s and Patterson’s classic text. 
渴望了解更多细节的读者可以去阅读 Hennessy’s 与 Patterson 最新版的经典书籍. 

Quick Quiz 
快速自测

3.1: Why should parallel programmers bother learning low-level properties of the hardware ? 
Wouldn’t it be easier, better, and more elegant to remain at a higher level of abstraction ? 
3.1: 为什么并行开发者不厌其烦的学习硬件底层的知识, 而不将时间投入到更加简单, 高效且优雅的高层抽象设计层级上? 

### 3.1 Overview 
### 3.1 概览

Careless reading of computer-system specification sheets might lead one to believe that CPU performance is a footrace on a clear track, as illustrated in Figure 3.1, where the race always goes to the swiftest. 
只是粗略阅读计算机系统规格表的话, 会很容易让人认为 CPU 的性能犹如在明晰跑道上竞技跑的选手一样, 总是跑得最快的先抢占到资源, 就像图中 3.1 所描绘的那样. 



Although there are a few CPU-bound benchmarks that approach the ideal case shown in Figure 3.1, the typical program more closely resembles an obstacle course than a race track. 
尽管在进行基准(benchmarks)测试时, 一些 CPU 密集型的测试用例得到的测试结果贴近图中 3.1 所描述的理想情况, 但更多的常规测试用例得到的指标则更像是一条阻碍赛道, 而不是一条阳关大道上奔跑的情景. 

This is because the internal architecture of CPUs has changed dramatically over the past few decades, courtesy of Moore's Law. These changes are described in the following sections. 

这一方面原因是因为 CPU 的内部架构在过去的十年中谨遵摩尔定律发生了戏剧性的迭代与升级. 这些迭代升级引起的变化会在后续的小节中一一论述. 

### 3.1.1 Pipelined CPUs 
In the 1980s, the typical microprocessor fetched an instruction, decoded it, and executed it, typically taking at least three clock cycles to complete one instruction before even starting the next. 
在 90 年代, 常规的微处理器至少会花费 3 个时钟周期来完成: 获取指令, 解析指令, 运行指令这些操作, 并且在完成之前是无法处理后续指令的.  

In contrast, the CPU of the late 1990s and of the 2000s execute many instructions simultaneously, using pipelines; superscalar techniques; out-of-order instruction and data handling; speculative execution, and more [HP 17, HP 11] in order to optimize the flow of instructions and data through the CPU. 
与之相反, 1990 末 至 2000 年初所生产的 CPU 能够借助于流水线设计独自运行多条指令; 超标量技术; 乱序指令与数据处理; 预测执行, 甚至是[HP 17, HP 11] 这些技术的引用目的只有一个: 对经由 CPU 处理的指令序列与数据进行优化.

Some cores have more than one hardware thread, which is variously called simultaneous multithreading (SMT) or hyperthreading (HT)[Fend73], each of which appears as an independent CPU to software, at least from a functional viewpoint. 
有些内核有多个硬件线程, 这种通常叫做同时多线程(SMT) 或是超线程(HT)[Fend73], 其中的每个线程从软件视角来看都是个独立的 CPU, 至少从软件中函数调用的视角来看是这样的. 

These modern hardware features can greatly improve performance, as illustrated by Figure 3.2.
当代将线程硬件化的这一种特性能极大程度提高性能, 如图 3.2 所示. 

Archieving full performance with a CPU having a long pipeline requires highly predictable control flow through the program. 
在长流水线的程序性能的提升, 需要对程序中的去控制流程有着很高的推断预测的能力. 
若要在具有长流水线的 CPU 实现全面性能的提升, 需要对程序中的控制流有这高度的推断与预测的能力. 

Suitable control flow can be provided by a program that executes primarily in tight loops, for example, arithmetic on large matrices or vectors. 

The CPU can then correctly predict that the branch at the end of the loop will be take in almost all cases, allowing the pipeline to be kept full and the CPU to execute at full speed. 

However, branch prediction is not always so easy. For example, consider a program with many loops, each of another example, consider an old-school object-oriented program with many virtual objects that can reference many different real objects, all with different implementations for frequently invoked member functions, resulting in many calls through pointer. 

In these cases, it is difficult or even impossible for the CPu to predict where the next branch might lead. 

Then either the CPU must stall waiting for execution to proceed far enough to be certain where that branch leands, or it must guess and then proceed using speculative execution. Although guessing works extremely well for programs with predictable control flow, for unpredictable branches (such as those in binary search) the guesses will frequently be wrong. 
























