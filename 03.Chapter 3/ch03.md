## Chapter 3
## Hardware and its Habits 
## 硬件及其特性

Most people intuitively understand that passing messages between systems is more expensive than performing simple calculations within the confines of a single system. 
大多数人会下意识认为系统间进行消息的传输所带来的系统开销要远高于单节点计算机上执行简单的计算. 


But it is also the case that communicating among threads within the confines of a single shared-memory system can also be quite expensive. 
但是同样在这个问题范畴内, 单个计算节点上多线程间彼此间竟有共享内存系统进行的通信其所带来的资源开销也同样高昂. 

This chapter therefore looks at the cost of synchornization and communication within a shared-memory system. 
所以本章就围绕(单个计算节点上的)在共享内存系统上所执行的同步操作与沟通所带来的系统开销来展开.  

These few pages can do no more than scratch the surface of shared-memory parallel hardware design; 
这一章节中的几页呢, 对于设计硬件中涉及到共享内存并行这个话题简直就是隔靴搔痒. 

readers desiring more detail would do well to start with a recent edition of Hennessy’s and Patterson’s classic text. 
渴望了解更多细节的读者可以去阅读 Hennessy’s 与 Patterson 最新版的经典书籍. 

Quick Quiz 
快速自测

3.1: Why should parallel programmers bother learning low-level properties of the hardware ? 
Wouldn’t it be easier, better, and more elegant to remain at a higher level of abstraction ? 
3.1: 为什么并行开发者不厌其烦的学习硬件底层的知识, 而不将时间投入到更加简单, 高效且优雅的高层抽象设计层级上? 

### 3.1 Overview 
### 3.1 概览

Careless reading of computer-system specification sheets might lead one to believe that CPU performance is a footrace on a clear track, as illustrated in Figure 3.1, where the race always goes to the swiftest. 
只是粗略阅读计算机系统规格表的话, 会很容易让人认为 CPU 的性能犹如在明晰跑道上竞技跑的选手一样, 总是跑得最快的先抢占到资源, 就像图中 3.1 所描绘的那样. 



Although there are a few CPU-bound benchmarks that approach the ideal case shown in Figure 3.1, the typical program more closely resembles an obstacle course than a race track. 
尽管在进行基准(benchmarks)测试时, 一些 CPU 密集型的测试用例得到的测试结果贴近图中 3.1 所描述的理想情况, 但更多的常规测试用例得到的指标则更像是一条阻碍赛道, 而不是一条阳关大道上奔跑的情景. 

This is because the internal architecture of CPUs has changed dramatically over the past few decades, courtesy of Moore's Law. These changes are described in the following sections. 

这一方面原因是因为 CPU 的内部架构在过去的十年中谨遵摩尔定律发生了戏剧性的迭代与升级. 这些迭代升级引起的变化会在后续的小节中一一论述. 

### 3.1.1 Pipelined CPUs 
In the 1980s, the typical microprocessor fetched an instruction, decoded it, and executed it, typically taking at least three clock cycles to complete one instruction before even starting the next. 

In contrast, the CPU of the late 1990s and of the 2000s execute many instructions simultaneously, using pipelines; superscalar techniques; out-of-order instruction and data handling; speculative execution, and more [HP 17, HP 11] in order to optimize the flow of instructions and data through the CPU. 

























